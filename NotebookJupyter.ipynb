{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](resources/title.png)\n",
    "\n",
    "# Tarea en Python usando PySpark para la asignatura de PAB\n",
    "\n",
    "### El objetivo de la pr치ctica es analizar los datos de indicadores de enfermedades cr칩nicas que se proporcionan en el portal dado, de d칩nde obtenemos un fichero .csv que contiene los datos a analizar. \n",
    "\n",
    "### Usaremos la API de RDDs y la de datasets\n",
    "\n",
    "### Autores:\n",
    "* Miguel Gonz치lez \n",
    "* Samuel Delgado\n",
    "* Victoria Cruz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyData.py con API RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Asthma', 9)\n",
      "('Chronic Kidney Disease', 4)\n",
      "('Older Adults', 4)\n",
      "('Mental Health', 3)\n",
      "('Immunization', 1)\n",
      "('Disability', 1)\n",
      "('Cancer', 20)\n",
      "('Oral Health', 9)\n",
      "('Tobacco', 16)\n",
      "('Reproductive Health', 3)\n",
      "('Arthritis', 10)\n",
      "('Diabetes', 20)\n",
      "('Cardiovascular Disease', 18)\n",
      "('Overarching Conditions', 16)\n",
      "('Alcohol', 16)\n",
      "('Chronic Obstructive Pulmonary Disease', 16)\n",
      "('Nutrition, Physical Activity, and Weight Status', 37)\n",
      "Computing time:  9.13486099243164\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "import sys\n",
    "import csv\n",
    "import time\n",
    "\n",
    "\n",
    "file_name = \"resources/U.S._Chronic_Disease_Indicators__CDI_.csv\"\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "logger = sc._jvm.org.apache.log4j\n",
    "logger.LogManager.getLogger(\"org\").setLevel(logger.Level.WARN)\n",
    "\n",
    "start_computing_time = time.time()\n",
    "\n",
    "file = sc \\\n",
    "    .textFile(file_name)\n",
    "header = file.first()\n",
    "\n",
    "d = file.filter(lambda line: line != header) \\\n",
    "    .map(lambda line: csv.reader([line], quotechar='\"', delimiter=',',\n",
    "                                 quoting=csv.QUOTE_ALL, skipinitialspace=True).__next__()) \\\n",
    "    .map(lambda r: (r[5], r[6])) \\\n",
    "    .groupByKey() \\\n",
    "    .map(lambda x: (x[0], set(x[1]))) \\\n",
    "    .mapValues(len) \\\n",
    "    .collect()\n",
    "\n",
    "for pair in d:\n",
    " print(pair)\n",
    "\n",
    "total_computing_time = time.time() - start_computing_time\n",
    "print(\"Computing time: \", str(total_computing_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyDataFrame.py con API datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------------+\n",
      "|               Topic|count(DISTINCT Question)|\n",
      "+--------------------+------------------------+\n",
      "|             Alcohol|                      16|\n",
      "|           Arthritis|                      10|\n",
      "|              Asthma|                       9|\n",
      "|              Cancer|                      20|\n",
      "|Cardiovascular Di...|                      18|\n",
      "|Chronic Kidney Di...|                       4|\n",
      "|Chronic Obstructi...|                      16|\n",
      "|            Diabetes|                      20|\n",
      "|          Disability|                       1|\n",
      "|        Immunization|                       1|\n",
      "|       Mental Health|                       3|\n",
      "|Nutrition, Physic...|                      37|\n",
      "|        Older Adults|                       4|\n",
      "|         Oral Health|                       9|\n",
      "|Overarching Condi...|                      16|\n",
      "| Reproductive Health|                       3|\n",
      "|             Tobacco|                      16|\n",
      "+--------------------+------------------------+\n",
      "\n",
      "+--------------------+------------+-----+\n",
      "|               Topic|LocationDesc|count|\n",
      "+--------------------+------------+-----+\n",
      "|Overarching Condi...|     Alabama|  733|\n",
      "|             Tobacco|     Alabama|  539|\n",
      "|        Immunization|     Alabama|   96|\n",
      "|             Alcohol|     Alabama|  593|\n",
      "|          Disability|     Alabama|   56|\n",
      "|Cardiovascular Di...|     Alabama| 1399|\n",
      "|           Arthritis|     Alabama|  768|\n",
      "|Nutrition, Physic...|     Alabama|  618|\n",
      "|       Mental Health|     Alabama|  133|\n",
      "|Chronic Kidney Di...|     Alabama|  236|\n",
      "|              Cancer|     Alabama|  262|\n",
      "|Chronic Obstructi...|     Alabama| 1416|\n",
      "|        Older Adults|     Alabama|  288|\n",
      "| Reproductive Health|     Alabama|   38|\n",
      "|              Asthma|     Alabama|  708|\n",
      "|         Oral Health|     Alabama|  205|\n",
      "|            Diabetes|     Alabama| 1442|\n",
      "|          Disability|      Alaska|   56|\n",
      "|         Oral Health|      Alaska|  205|\n",
      "|           Arthritis|      Alaska|  768|\n",
      "+--------------------+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Computing time:  16.65758991241455\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as func\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "file_name = \"resources/U.S._Chronic_Disease_Indicators__CDI_.csv\"\n",
    "\n",
    "spark_session = SparkSession \\\n",
    "    .builder \\\n",
    "    .getOrCreate()\n",
    "\n",
    "logger = spark_session._jvm.org.apache.log4j\n",
    "logger.LogManager.getLogger(\"org\").setLevel(logger.Level.WARN)\n",
    "\n",
    "start_computing_time = time.time()\n",
    "\n",
    "data_frame = spark_session \\\n",
    "    .read \\\n",
    "    .format(\"csv\") \\\n",
    "    .options(header='true', inferschema='true') \\\n",
    "    .load(file_name)\n",
    "\n",
    "data_frame \\\n",
    "    .groupBy(\"Topic\") \\\n",
    "    .agg(func.countDistinct(\"Question\")) \\\n",
    "    .sort(\"Topic\") \\\n",
    "    .show()\n",
    "\n",
    "data_frame \\\n",
    "    .groupBy(\"Topic\", \"LocationDesc\") \\\n",
    "    .count() \\\n",
    "    .sort(\"LocationDesc\") \\\n",
    "    .show()\n",
    "\n",
    "total_computing_time = time.time() - start_computing_time\n",
    "print(\"Computing time: \", str(total_computing_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
