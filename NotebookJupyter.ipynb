{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](resources/title.png)\n",
    "\n",
    "# Tarea en Python usando PySpark para la asignatura de PAB\n",
    "\n",
    "### El objetivo de la pr치ctica es analizar los datos de indicadores de enfermedades cr칩nicas que se proporcionan en el portal dado, de d칩nde obtenemos un fichero .csv que contiene los datos a analizar. \n",
    "\n",
    "### Usaremos la API de RDDs y la de datasets\n",
    "\n",
    "### Autores:\n",
    "* Miguel Gonz치lez \n",
    "* Samuel Delgado\n",
    "* Victoria Cruz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyData.py con API RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Asthma', 9)\n",
      "('Chronic Kidney Disease', 4)\n",
      "('Older Adults', 4)\n",
      "('Mental Health', 3)\n",
      "('Immunization', 1)\n",
      "('Disability', 1)\n",
      "('Cancer', 20)\n",
      "('Oral Health', 9)\n",
      "('Tobacco', 16)\n",
      "('Reproductive Health', 3)\n",
      "('Arthritis', 10)\n",
      "('Diabetes', 20)\n",
      "('Cardiovascular Disease', 18)\n",
      "('Overarching Conditions', 16)\n",
      "('Alcohol', 16)\n",
      "('Chronic Obstructive Pulmonary Disease', 16)\n",
      "('Nutrition, Physical Activity, and Weight Status', 37)\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "import sys\n",
    "import csv\n",
    "import time\n",
    "\n",
    "\n",
    "file_name = \"data/data.csv\"\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "logger = sc._jvm.org.apache.log4j\n",
    "logger.LogManager.getLogger(\"org\").setLevel(logger.Level.WARN)\n",
    "\n",
    "start_computing_time = time.time()\n",
    "\n",
    "file = sc \\\n",
    "    .textFile(file_name)\n",
    "header = file.first()\n",
    "\n",
    "d = file.filter(lambda line: line != header) \\\n",
    "    .map(lambda line: csv.reader([line], quotechar='\"', delimiter=',',\n",
    "                                 quoting=csv.QUOTE_ALL, skipinitialspace=True).__next__()) \\\n",
    "    .map(lambda r: (r[5], r[6])) \\\n",
    "    .groupByKey() \\\n",
    "    .map(lambda x: (x[0], set(x[1]))) \\\n",
    "    .mapValues(len) \\\n",
    "    .collect()\n",
    "    \n",
    "total_computing_time = time.time() - start_computing_time\n",
    "\n",
    "for pair in d:\n",
    "    print(pair)\n",
    "    \n",
    "print(\"Computing time: \", str(total_computing_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyDataFrame.py con API datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
